{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "RNN-task.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNwtRXJ07nRF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "cdd472bb-c3b5-45cb-ba03-c9ec8f83f1b6"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2020-01-30 19:30:18--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-01-30 19:30:18 (54.4 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peIO4rjk7j08",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLQ-A46Y7j1O",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "LVIJ-Knl7j1U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "af820bc6-7c3a-459e-d66d-039e94df5fbd"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YX8xfwlM7j1c",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "sTniTKi67j1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "Cge8s0WS7j1o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "f08aa4a4-9fb5-44c3-d0be-83abda43f436"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "oSZVZxso7j1v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "de4111da-ca79-458f-99dd-5eff87982c11"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ9/MLCMOfTOzjPx/p/4cUF1Gcl0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AU4PhrYc7j15",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "uLDrh7nk7j17",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "697c6ea1-270c-4fe4-a5e1-83e893641231"
      },
      "source": [
        "tokens = set(''.join(names)) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "# join all the names together and then create a set of characters from them. \n",
        "tokens.add(pad_token) # add this to the nd of the set\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['K', 'c', 'F', 'A', 'T', 'u', 's', 'Y', 'n', 'H', ' ', 'o', 'a', 'V', 'k', 'e', 'z', 'D', 'J', 'p', 'I', 'M', 'v', 'q', 'h', 'w', 'r', 'S', 'R', 'y', 'U', '#', 'L', 'W', 'x', 'l', 'N', 'g', 'f', 'G', 'O', 't', 'P', 'Q', 'b', 'd', 'X', 'Z', 'B', 'E', 'i', \"'\", 'm', '-', 'C', 'j']\n",
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDMDBOev7j2C",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "QwjEcb_p7j2E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "088506cf-3d12-46ef-af1e-5d593f73d39b"
      },
      "source": [
        "token_to_id = {word : i for i, word in enumerate(tokens)} ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "print(token_to_id)\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'K': 0, 'c': 1, 'F': 2, 'A': 3, 'T': 4, 'u': 5, 's': 6, 'Y': 7, 'n': 8, 'H': 9, ' ': 10, 'o': 11, 'a': 12, 'V': 13, 'k': 14, 'e': 15, 'z': 16, 'D': 17, 'J': 18, 'p': 19, 'I': 20, 'M': 21, 'v': 22, 'q': 23, 'h': 24, 'w': 25, 'r': 26, 'S': 27, 'R': 28, 'y': 29, 'U': 30, '#': 31, 'L': 32, 'W': 33, 'x': 34, 'l': 35, 'N': 36, 'g': 37, 'f': 38, 'G': 39, 'O': 40, 't': 41, 'P': 42, 'Q': 43, 'b': 44, 'd': 45, 'X': 46, 'Z': 47, 'B': 48, 'E': 49, 'i': 50, \"'\": 51, 'm': 52, '-': 53, 'C': 54, 'j': 55}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "tnPUMrOU7j2N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "1O61X20H7j2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "8b93cea5-6536-4602-ee04-15520b61a5bf"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[10  3 44 12 37 12 15 35 31]\n",
            " [10 39 35 11 26 29 31 31 31]\n",
            " [10 42 26 50  6  6 50 15 31]\n",
            " [10 39 50 11 22 12  8  8 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_ybIx_h7j2a",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "bt6-EfFc7j2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "a8690922-a4da-42ac-e836-7341d40dc2bb"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "Dfh1N__n7j2l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation='tanh') ### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation='softmax') ### YOUR CODE HERE "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXFqc4d47j2v",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "3KpIeBEc7j2v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t]) ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next) ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23-tCfp37j21",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "6oejG0Rk7j23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gF-M18N7j29",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "C00zUZO-7j3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEgduGIf7j3D",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "e4P4MWf07j3G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = -tf.reduce_mean(answers_matrix * tf.log(predictions_matrix)) ### YOUR CODE HERE\n",
        "\n",
        "# =  -y * log(y_hat)\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HwQVu7r7j3V",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "lZUzPk1d7j3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "a5e42359-600e-4ac4-9866-ab4581ab191f"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nchrolVLK5TTQK6WUy/0/ew9gWovJ42oAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1g_uSlw7j3d",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "Ksuly8fQ7j3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "ChVhRpmX7j3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "8PbNqQxB7j3o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "9fbc5d50-2d24-4f65-940c-86fb92273d58"
      },
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Tfio\n",
            " Dolk\n",
            " Alviobe\n",
            " Barelinsr\n",
            " Gya\n",
            " Maon\n",
            " Rodideelda\n",
            " Dolme\n",
            " Errman\n",
            " Bemer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "5wZJTj-s7j3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "24b36cf4-edd0-4a4b-ecb4-9a7f2384206a"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpy\n",
            " Trumphttca\n",
            " Trump\n",
            " Trumpad\n",
            " Trump\n",
            " Trumphanna\n",
            " Trumpa\n",
            " Trumphe\n",
            " Trumpri\n",
            " Trumpian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92LCYa6r7j3z",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "37whtqY47j3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"m4tAgVPpf4qvC6w9\"\n",
        "COURSERA_EMAIL = \"cooper.chastain@att.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "kxEFKShB7j35",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "e432a1b6-d5dc-4346-9c7b-4ee63fcf5532"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKa5S-N27j39",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "FyXTBhQ17j3-",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "0Cotfs3n7j4A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c31a54e7-24a2-4bc7-c2bd-7f12dc3b76aa"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-49-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-49-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-5f3812e903bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpredicted_probas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM outputs for each step [batch,time,n_tokens]:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 2753\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   2754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2243\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2168\u001b[0m         expand_composites=True)\n\u001b[1;32m   2169\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2172\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence_or_composite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2705\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    882\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[0;31m# Keras cells always wrap state as list, even if it's a single tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_keras_rnn_cell\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 386\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2144\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2146\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2147\u001b[0m       \u001b[0;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m       \u001b[0;31m# constrained to set self.built.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(instance, input_shape)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_tuples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m     \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Return shapes from `fn` as TensorShapes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0moutput_shape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    449\u001b[0m       raise ValueError(\"Expected inputs.shape[-1] to be known, saw shape: %s\" %\n\u001b[1;32m    450\u001b[0m                        str(inputs_shape))\n\u001b[0;32m--> 451\u001b[0;31m     \u001b[0m_check_supported_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0minput_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_check_supported_dtypes\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1345\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m     raise ValueError(\"RNN cell only supports floating point inputs, \"\n\u001b[0;32m-> 1347\u001b[0;31m                      \"but saw dtype: %s\" % dtype)\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: RNN cell only supports floating point inputs, but saw dtype: <dtype: 'int32'>"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDaobkQg7j4D",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "B9bFqxeF7j4D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "3a19ff91-d72c-492b-816e-267adbc5edc2"
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "bguSxcMq7j4I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "5aa7ffb1-9910-4a51-af48-0c379d87d457"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-51-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}