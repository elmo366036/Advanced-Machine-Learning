{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming assignment we will illustrate a very severe data leakage, that can often be found in competitions, where the pairs of object should be scored, e.g. predict $1$ if two objects belong to the same class and $0$ otherwise. \n",
    "\n",
    "The data in this assignment is taken from a real competition, and the funniest thing is that *we will not use training set at all* and achieve almost 100% accuracy score! We will just exploit the leakage.\n",
    "\n",
    "Now go through the notebook and complete the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coop's Analysis of the Data Leakage\n",
    "I have spent hours on this and while I was able to get the code to work I am nut sure if I really understand what is going on. I will try to summarize\n",
    "\n",
    "We know that 50% of the test set is positive (class 1 out of [0,1])\n",
    "\n",
    "We know that the total number of pairs is much higher than the number of positive pairs in the test set. This suggests that the test set was constructed using an algorithm. Perhaps we can exploit this or even determine what the algorithm was and use it to predict the classes of the test set.\n",
    "\n",
    "We calculated the similarity between \"what the FirstIDs connect to\" and \"what the SecondIds connect to\" using a dot product of sparse matrices. The result is a similarity score for each pairId that describes how similar the connectivity of each Id in the pair are to each other.\n",
    "\n",
    "The higher the similarity score, the more likely that the two Ids in the pair should be classified as a 1.\n",
    "\n",
    "We identified a threshold of similarity score that we should use for each pairID and chose 1 when the similarity score is above this threshold. We know to choose 1 when the score is above the threshold because as the score increases, the similarity between the connectivity increases. As the similarity increases, the likelihood of belonging to the same class increases.\n",
    "\n",
    "We determined the threshold by examining the number of occurrences of each similar score and compared with the number of 1's that we expected (184,225).  Setting f > 15 gets us closest to that value.\n",
    "\n",
    "This achieved an accuracy score of 0.999609.\n",
    "\n",
    "To summarize, we can get near perfect predictions because we know there is a strong relationship (i.e. correlation) between \"what the FirstIDs connect to\" and \"what the SecondIds connect to.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pairId is a combination of a FirstId and a SecondId. It can be modeled as an edge.\n",
    "# there are 368,550 such edges in the test set, but there are 346,489,650 potential pairIds.\n",
    "# of these 368,550 edges, we know that 184,275 are in class 1 and 184, 275 in class 0 because 50% are in one class\n",
    "# there are 26,325 unique First/Second Ids\n",
    "\n",
    "# create an incidence matrix that has First/Second Ids for both row and column indices. \n",
    "# the dimensionality of this matrix is (# First/Second Ids + 1, # First/Second Ids + 1)\n",
    "#    mark the coordinates in the matrix corresponding to the pairId (FirstId, SecondId) \n",
    "#    and its reverse (SecondId, FirstId) with a 1. the rest are zeros. use sparse matrix\n",
    "\n",
    "# in the incidence matrix, there are 736,872 ones and many, many more zeros. \n",
    "\n",
    "# the incidence matrix thus represents the connectivity between FirstIds and SecondIs\n",
    "\n",
    "# we will then measure the similiarty of what FirstIds connect to with what SecondIds connect to. \n",
    "# we do this by taking the dot produce of 'FirstId connectivity' with 'SeconfId connectivity'\n",
    "# 'FirstId connectivity' can be derived from the incicence matrix by taking only the rows with\n",
    "#   row indces that correspond to FirstIds. \n",
    "# the same is true for 'SecondId connctivity'\n",
    "\n",
    "# the dot product represents the degree of similiarity between 'FirstId connectivity' and 'SecondId connectivity'\n",
    "\n",
    "# there are only a few unique scores for the dot product and we know how often those scores occur. \n",
    "# we can use the score as a feature because each FirstId / SecondId pair will have a score. \n",
    "\n",
    "# since we know that 50% of the test data should be marked as 1, we know the exact number (184,225). \n",
    "# we can use the score to determine whether to mark a class as a 0 or 1. \n",
    "# the closest we can get to 184,225 is to set all Pairs to 1 if the score (f) is greater than 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the test data. Note, that we don't have any training data here, just test data. Moreover, *we will not even use any features* of test objects. All we need to solve this task is the file with the indices for the pairs, that we need to compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data with test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairId</th>\n",
       "      <th>FirstId</th>\n",
       "      <th>SecondId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1427</td>\n",
       "      <td>8053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>17044</td>\n",
       "      <td>7681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>19237</td>\n",
       "      <td>20966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8005</td>\n",
       "      <td>20765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16837</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3657</td>\n",
       "      <td>12504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2836</td>\n",
       "      <td>7582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6136</td>\n",
       "      <td>6111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>23295</td>\n",
       "      <td>9817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>6621</td>\n",
       "      <td>7672</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pairId  FirstId  SecondId\n",
       "0       0     1427      8053\n",
       "1       1    17044      7681\n",
       "2       2    19237     20966\n",
       "3       3     8005     20765\n",
       "4       4    16837       599\n",
       "5       5     3657     12504\n",
       "6       6     2836      7582\n",
       "7       7     6136      6111\n",
       "8       8    23295      9817\n",
       "9       9     6621      7672"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../readonly/data_leakages_data/test_pairs.csv')\n",
    "test.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can think that there is a test dataset of images, and each image is assigned a unique `Id` from $0$ to $N-1$ (N -- is the number of images). In the dataframe from above `FirstId` and `SecondId` point to these `Id`'s and define pairs, that we should compare: e.g. do both images in the pair belong to the same class or not. So, for example for the first row: if images with `Id=1427` and `Id=8053` belong to the same class, we should predict $1$, and $0$ otherwise. \n",
    "\n",
    "But in our case we don't really care about the images, and how exactly we compare the images (as long as comparator is binary).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We suggest you to try to solve the puzzle yourself first.** You need to submit a `.csv` file with columns `pairId` and `Prediction` to the grader. The number of submissions allowed is made pretty huge to let you explore the data without worries. The returned score should be very close to $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you do not want to think much** -- scroll down and follow the instructions below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairId</th>\n",
       "      <th>FirstId</th>\n",
       "      <th>SecondId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>368550.000000</td>\n",
       "      <td>368550.000000</td>\n",
       "      <td>368550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>184274.500000</td>\n",
       "      <td>10863.601118</td>\n",
       "      <td>11950.398882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>106391.365192</td>\n",
       "      <td>7280.190939</td>\n",
       "      <td>7602.814820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>92137.250000</td>\n",
       "      <td>4574.000000</td>\n",
       "      <td>5698.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>184274.500000</td>\n",
       "      <td>9886.000000</td>\n",
       "      <td>10512.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>276411.750000</td>\n",
       "      <td>16512.000000</td>\n",
       "      <td>18782.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>368549.000000</td>\n",
       "      <td>26324.000000</td>\n",
       "      <td>26324.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pairId        FirstId       SecondId\n",
       "count  368550.000000  368550.000000  368550.000000\n",
       "mean   184274.500000   10863.601118   11950.398882\n",
       "std    106391.365192    7280.190939    7602.814820\n",
       "min         0.000000       0.000000       0.000000\n",
       "25%     92137.250000    4574.000000    5698.000000\n",
       "50%    184274.500000    9886.000000   10512.000000\n",
       "75%    276411.750000   16512.000000   18782.000000\n",
       "max    368549.000000   26324.000000   26324.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairId</th>\n",
       "      <th>FirstId</th>\n",
       "      <th>SecondId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186443</th>\n",
       "      <td>186443</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218927</th>\n",
       "      <td>218927</td>\n",
       "      <td>2551</td>\n",
       "      <td>2551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221189</th>\n",
       "      <td>221189</td>\n",
       "      <td>8046</td>\n",
       "      <td>8046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228783</th>\n",
       "      <td>228783</td>\n",
       "      <td>2799</td>\n",
       "      <td>2799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293834</th>\n",
       "      <td>293834</td>\n",
       "      <td>292</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327330</th>\n",
       "      <td>327330</td>\n",
       "      <td>10404</td>\n",
       "      <td>10404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pairId  FirstId  SecondId\n",
       "186443  186443      300       300\n",
       "218927  218927     2551      2551\n",
       "221189  221189     8046      8046\n",
       "228783  228783     2799      2799\n",
       "293834  293834      292       292\n",
       "327330  327330    10404     10404"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['FirstId'] == test['SecondId']]\n",
    "# there are 6 pairIds where FirstId and SecondId are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26325\n",
      "26310\n"
     ]
    }
   ],
   "source": [
    "print(test['FirstId'].nunique())\n",
    "print(test['SecondId'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 3)\n",
      "(24, 3)\n"
     ]
    }
   ],
   "source": [
    "print(test[test.duplicated(subset=['FirstId', 'SecondId'])].shape)\n",
    "print(test[test.duplicated(subset=['FirstId', 'SecondId'], keep = False)].shape)\n",
    "\n",
    "# there are 12 pairs of FirstId, Second Id that are repeated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and leakage intuition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already know, the key to discover data leakages is careful EDA. So let's start our work with some basic data exploration and build an intuition about the leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, check, how many different `id`s are there: concatenate `FirstId` and `SecondId` and print the number of unique elements. Also print minimum and maximum value for that vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26325 0 26324\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "concat = test['FirstId'].append(test['SecondId'])\n",
    "print(concat.nunique(), concat.unique().min(), concat.unique().max())\n",
    "\n",
    "# there are 26,325 unique First/Second Ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then print how many pairs we need to classify (it is basically the number of rows in the test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368550"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now print, how many distinct pairs it would be possible to create out of all \"images\" in the dataset?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346489650.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "distinct_pairs = (26325)*(26325-1)/2 \n",
    "distinct_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the number of pairs we are given to classify is very very small compared to the total number of pairs. \n",
    "\n",
    "To exploit the leak we need to **assume (or prove)**, that the total number of positive pairs is small, compared to the total number of pairs. For example: think about an image dataset with $1000$ classes, $N$ images per class. Then if the task was to tell whether a pair of images belongs to the same class or not, we would have $1000\\frac{N(N-1)}{2}$ positive pairs, while total number of pairs was $\\frac{1000N(1000N - 1)}{2}$.\n",
    "\n",
    "Another example: in [Quora competitition](https://www.kaggle.com/c/quora-question-pairs) the task was to classify whether a pair of qustions are duplicates of each other or not. Of course, total number of question pairs is very huge, while number of duplicates (positive pairs) is much much smaller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, let's get a fraction of pairs of class `1`. We just need to submit a constant prediction \"all ones\" and check the returned accuracy. Create a dataframe with columns `pairId` and `Prediction`, fill it and export it to `.csv` file. Then submit to grader and examine grader's output. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we assumed the total number of pairs is much higher than the number of positive pairs, but it is not the case for the test set. It means that the test set is constructed not by sampling random pairs, but with a specific sampling algorithm. Pairs of class `1` are oversampled.\n",
    "\n",
    "Now think, how we can exploit this fact? What is the leak here? If you get it now, you may try to get to the final answer yourself, othewise you can follow the instructions below.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pairId</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pairId  Prediction\n",
       "0       0           1\n",
       "1       1           1\n",
       "2       2           1\n",
       "3       3           1\n",
       "4       4           1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "df = pd.DataFrame()\n",
    "df['pairId'] = test['pairId']\n",
    "df['Prediction'] = 1\n",
    "df.to_csv('submission.csv', index=False)\n",
    "df.head()\n",
    "\n",
    "# grader reports accuracy score of 0.5. this means that half of the test cases are 1 and half 0. \n",
    "# if we assume that the number of positive pairs in the training set is much less than 1, and combine\n",
    "#     this with the fact that half of the test set pairs are 1, we can deduce that the test set is\n",
    "#     not randomly generated. there are too many pairs of 1 in test\n",
    "# of the 368,550 pairs, 184,275 will be classified as 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a magic feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will build a magic feature, that will solve the problem almost perfectly. The instructions will lead you to the correct solution, but please, try to explain the purpose of the steps we do to yourself -- it is very important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incidence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to build an [incidence matrix](https://en.wikipedia.org/wiki/Incidence_matrix). You can think of pairs `(FirstId, SecondId)` as of edges in an undirected graph. \n",
    "\n",
    "The incidence matrix is a matrix of size `(maxId + 1, maxId + 1)`, where each row (column) `i` corresponds `i-th` `Id`. In this matrix we put the value `1` to the position `[i, j]`, if and only if a pair `(i, j)` or `(j, i)` is present in  a given set of pais `(FirstId, SecondId)`. All the other elements in the incidence matrix are zeros.   \n",
    "\n",
    "**Important!** The incidence matrices are typically very very sparse (small number of non-zero values). At the same time incidence matrices are usually huge in terms of total number of elements, and it is **impossible to store them in memory in dense format**. But due to their sparsity incidence matrices **can be easily represented as sparse matrices**. If you are not familiar with sparse matrices, please see [wiki](https://en.wikipedia.org/wiki/Sparse_matrix) and [scipy.sparse reference](https://docs.scipy.org/doc/scipy/reference/sparse.html). Please, use any of `scipy.sparse` constructors to build incidence matrix. \n",
    "\n",
    "For example, you can use this constructor: `scipy.sparse.coo_matrix((data, (i, j)))`. We highly recommend to learn to use different `scipy.sparse` constuctors, and matrices types, but if you feel you don't want to use them, you can always build this matrix with a simple `for` loop. You will need first to create a matrix using `scipy.sparse.coo_matrix((M, N), [dtype])` with an appropriate shape `(M, N)` and then iterate through `(FirstId, SecondId)` pairs and fill corresponding elements in matrix with ones. \n",
    "\n",
    "**Note**, that the matrix should be symmetric and consist only of zeros and ones. It is a way to check yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(228, 2)\n"
     ]
    }
   ],
   "source": [
    "#inc_mat = # YOUR CODE GOES HERE (but probably you will need to write few more lines before)\n",
    "#i = test['FirstId'].max() + 1\n",
    "#j = test['SecondId'].max() + 1\n",
    "#scipy.sparse.coo_matrix((data, (i, j))\n",
    "\n",
    "# need to create a sparse matrix of First/Second Ids serving as both row and column indices. \n",
    "# we'll create two lists and concatenate them. one is for forward edges (FirstId -> SecondId)\n",
    "#   and vice versa. we'll concatenate the lists and then remove dupicates. \n",
    "# create forward edges and backward edges; concatenate; remove duplicate entries (there are 228)\n",
    "edges_fw = test[['FirstId', 'SecondId']].values\n",
    "edges_bw = test[['SecondId', 'FirstId']].values\n",
    "edges = np.concatenate([edges_fw, edges_bw])\n",
    "\n",
    "# somehow this operation results in 228 duplicated rows\n",
    "s = pd.DataFrame(edges)\n",
    "print(s[s.duplicated()].shape)\n",
    "\n",
    "edges = np.unique(edges, axis=0)\n",
    "#print(edges.shape)\n",
    "\n",
    "# create sparse matrix\n",
    "# create a vector of ones corresponding to the number of unique edges\n",
    "data = np.ones(len(edges))\n",
    "\n",
    "# determine row and column indices\n",
    "i = row_indices = edges[:,0]      # first column of Ids   FirstId : SecondId\n",
    "j = column_indices = edges[:, 1]  # second column of Ids  SecondId : FirstId\n",
    "\n",
    "# ones are placed where (FirstId, SecondId) & vice versa correspond to a pair in test\n",
    "inc_mat = scipy.sparse.coo_matrix((data, (i, j)))\n",
    "'''\n",
    "  coo_matrix((data, (i, j)), [shape=(M, N)])\n",
    "    to construct from three arrays:\n",
    "            data[:] the entries of the matrix, in any order\n",
    "            i[:] the row indices of the matrix entries\n",
    "            j[:] the column indices of the matrix entries\n",
    "    Where A[i[k], j[k]] = data[k]. When shape is not specified, it is inferred from the index arrays\n",
    "'''\n",
    "\n",
    "# Sanity checks\n",
    "assert inc_mat.max() == 1\n",
    "assert inc_mat.sum() == 736872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26325, 26325)\n"
     ]
    }
   ],
   "source": [
    "print(inc_mat.shape)\n",
    "\n",
    "# there are 26,325 unique First/Second Ids and 736,872 edges (or, unique relationships between FirstId and SecondId)\n",
    "# the number of 1's in the matrix is equal to the sum over the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# inc_mat is a matrix with FirstIds and SecondIds serving as both the row and column indices. \n",
    "# the matrix is marked with zeros except where there is a relationship, or an edge,\n",
    "#   between a FirstId and a SecondId or vice versa\n",
    "\n",
    "# the matrix is created as follows:\n",
    "#   create a matrix m of zeros of size row, column\n",
    "#   create a vector v of ones of size row\n",
    "#   iterate simultaneously through row and column\n",
    "#      maintain the sum of each row, column pair by adding the corresponding value from data\n",
    "#   collapse the row, column sums into matrix m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is convenient to have matrix in `csr` format eventually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inc_mat = inc_mat.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now build the magic feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did we build the incidence matrix? We can think of the rows in this matix as of representations for the objects. `i-th` row is a representation for an object with `Id = i`. Then, to measure similarity between two objects we can measure similarity between their representations. And we will see, that such representations are very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now select the rows from the incidence matrix, that correspond to `test.FirstId`'s, and `test.SecondId`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368550, 26325)\n",
      "(368550, 26325)\n"
     ]
    }
   ],
   "source": [
    "# Note, scipy goes crazy if a matrix is indexed with pandas' series. \n",
    "# So do not forget to convert `pd.series` to `np.array`\n",
    "# These lines should normally run very quickly \n",
    "rows_FirstId   = inc_mat[np.array(test['FirstId'])] # YOUR CODE GOES HERE\n",
    "rows_SecondId  = inc_mat[np.array(test['SecondId'])] # YOUR CODE GOES HERE\n",
    "\n",
    "print(rows_FirstId.shape)\n",
    "print(rows_SecondId.shape)\n",
    "\n",
    "# This code retrieves from the incidence matrix two sets of rows: one indexed by FirstId\n",
    "#   and the other by SecondId. \n",
    "# Each is a sparse matrix. \n",
    "# Each row can be intepretted as telling us the edges between the row index and the\n",
    "#   column indexes (which are all the unique First/Second Ids)\n",
    "# Each row tells us the connectivity between a First/Second Id and all the others. \n",
    "\n",
    "# rows_First_Id tells us what FirstId connects to\n",
    "# rows_Second_Id tells us what SecondId connects to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our magic feature will be the *dot product* between representations of a pair of objects. Dot product can be regarded as similarity measure -- for our non-negative representations the dot product is close to 0 when the representations are different, and is huge, when representations are similar. \n",
    "\n",
    "Now compute dot product between corresponding rows in `rows_FirstId` and `rows_SecondId` matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note, that in order to do pointwise multiplication in scipy.sparse you need to use function `multiply`\n",
    "# regular `*` corresponds to matrix-matrix multiplication\n",
    "\n",
    "#f = # YOUR CODE GOES HERE\n",
    "\n",
    "# dot product has to be calculated 'manually' (element wise multiplication followed by summation)\n",
    "f = rows_FirstId.multiply(rows_SecondId)\n",
    "f = f.sum(axis=1)\n",
    "f = np.squeeze(np.asarray(f)) # go from (368550, 1) to (268440, )\n",
    "\n",
    "# Sanity check\n",
    "assert f.shape == (368550, )\n",
    "\n",
    "# what does the dot product tell us?\n",
    "# it indicates the similiarity between what FirstIds connect to and what SecondIds connect to\n",
    "# each Pair will now have a similiarity score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is it! **We've built our magic feature.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From magic feature to binary predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how do we convert this feature into binary predictions? We do not have a train set to learn a model, but we have a piece of information about test set: the baseline accuracy score that you got, when submitting constant. And we also have a very strong considerations about the data generative process, so probably we will be fine even without a training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may try to choose a thresold, and set the predictions to 1, if the feature value `f` is higer than the threshold, and 0 otherwise. What threshold would you choose? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we find a right threshold? Let's first examine this feature: print frequencies (or counts) of each value in the feature `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 14.,  15.,  19.,  20.,  21.,  28.,  35.]), array([183279,    852,    546, 183799,      6,     54,     14]))\n"
     ]
    }
   ],
   "source": [
    "# For example use `np.unique` function, check for flags\n",
    "\n",
    "print(np.unique(f, return_counts=True))\n",
    "\n",
    "# there are only 7 unique values of the dot product. Look at the return counts.\n",
    "# we know that 50% of the test (184,275) items must be classified as 1 \n",
    "# we can use the similiaity score as a proxy to split the test set into two parts\n",
    "# \n",
    "# all return counts occur when dot product is greater than 14\n",
    "# of the 368,550 pairs, 104,275 will be classified as 1\n",
    "# we clearly can get that number by setting f > 15. \n",
    "# this will cause 184,419 of the pairs to be set to 1 and results in \n",
    "#    an accuracy score of 0.999609. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see how this feature clusters the pairs? Maybe you can guess a good threshold by looking at the values? \n",
    "\n",
    "In fact, in other situations it can be not that obvious, but in general to pick a threshold you only need to remember the score of your baseline submission and use this information. Do you understand why and how?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a threshold below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = f > 15 # SET THRESHOLD HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, let's create a submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = test.loc[:,['pairId']]\n",
    "submission['Prediction'] = pred.astype(int)\n",
    "\n",
    "submission.to_csv('submission_4.csv', index=False)\n",
    "\n",
    "# with f > 15, score was 0.999609 \n",
    "# with f > 14, score was 0.997298\n",
    "# with f > 19, score was 0.998128\n",
    "# best result is f > 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now submit it to the grader! It is not possible to submit directly from this notebook, as we need to submit a `csv` file, not a single number (limitation of Coursera platform). \n",
    "\n",
    "To download `submission.csv` file that you've just produced <a href='./submission.csv'>click here</a> (if the link opens in browser, right-click on it and shoose \"Save link as\"). Then go to [assignment page](https://www.coursera.org/learn/competitive-data-science/programming/KsASv/data-leakages/submission) and submit your `.csv` file in 'My submission' tab.\n",
    "\n",
    "\n",
    "If you did everything right, the score should be very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally:** try to explain to yourself, why the whole thing worked out. In fact, there is no magic in this feature, and the idea to use rows in the incidence matrix can be intuitively justified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, it is not the only leak in this dataset. There is another totally different way to get almost 100% accuracy. Try to find it!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
